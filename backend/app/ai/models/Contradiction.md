# H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG H·ªÜ TH·ªêNG PH√ÅT HI·ªÜN M√ÇU THU·∫™N

## üìö T·ªïng quan

H·ªá th·ªëng ph√°t hi·ªán m√¢u thu·∫´n (Contradiction Detection) s·ª≠ d·ª•ng **Natural Language Inference (NLI)** model ƒë·ªÉ ph√¢n t√≠ch vƒÉn b·∫£n v√† t√¨m c√°c c√¢u m√¢u thu·∫´n v·ªõi nhau.

### C√°c th√†nh ph·∫ßn ch√≠nh:

1. **`contradictions.py`** - Core module ch·ª©a h√†m ph√¢n t√≠ch ch√≠nh
2. **`nlp.py`** - Utils ƒë·ªÉ t√°ch c√¢u t·ª´ vƒÉn b·∫£n
3. **Models:**
   - **Base Model**: `MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7` (ƒêa ng√¥n ng·ªØ)
   - **Fine-tuned Model**: Model ƒë√£ fine-tune cho ti·∫øng Vi·ªát (trong `fine tune/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/`)

---

## üöÄ C√°ch s·ª≠ d·ª•ng c∆° b·∫£n

### 1. Import

```python
from app.ai.models.contradictions import check_contradictions
```

### 2. S·ª≠ d·ª•ng Fine-tuned Model (Khuy√™n d√πng cho ti·∫øng Vi·ªát)

```python
text = """
Minh lu√¥n n√≥i r·∫±ng anh ch∆∞a bao gi·ªù r·ªùi kh·ªèi Vi·ªát Nam.
Anh k·ªÉ r·∫±ng l·∫ßn ƒë·∫ßu ƒë·∫øn Nh·∫≠t B·∫£n l√† v√†o nƒÉm 2019.
Anh cho bi·∫øt m√¨nh gh√©t s·ª± ·ªìn √†o n√™n hi·∫øm khi ra ngo√†i v√†o bu·ªïi t·ªëi.
T·ªëi n√†o Minh c≈©ng ƒëi u·ªëng c√† ph√™ c√πng b·∫°n b√® ƒë·ªÉ th∆∞ gi√£n.
"""

result = check_contradictions(
    text=text,
    mode="finetuned",  # S·ª≠ d·ª•ng fine-tuned model
    threshold=0.75
)

# In k·∫øt qu·∫£
print(f"T√¨m th·∫•y {result['total_contradictions']} m√¢u thu·∫´n")
for c in result['contradictions']:
    print(f"- [{c['id']}] Confidence: {c['confidence']:.2%}")
    print(f"  C√¢u {c['sentence1_index']}: {c['sentence1']}")
    print(f"  C√¢u {c['sentence2_index']}: {c['sentence2']}")
```

### 3. S·ª≠ d·ª•ng Base Model

```python
result = check_contradictions(
    text=text,
    mode="base",  # S·ª≠ d·ª•ng base model
    threshold=0.75
)
```

---

## üìñ H√†m `check_contradictions()`

### Signature

```python
def check_contradictions(
    text: str,
    mode: str = "finetuned",
    threshold: float = 0.75,
    use_embeddings_filter: bool = True,
    embedding_model_name: str = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
    top_k: int = 50,
    sim_min: float = 0.30,
    sim_max: float = 0.98,
    batch_size: int = 8,
    max_length: int = 128,
) -> Dict[str, Any]
```

### Parameters

| Parameter | Type | Default | M√¥ t·∫£ |
|-----------|------|---------|-------|
| `text` | `str` | **required** | ƒêo·∫°n vƒÉn b·∫£n c·∫ßn ph√¢n t√≠ch |
| `mode` | `str` | `"finetuned"` | Ch·∫ø ƒë·ªô model: `"base"` ho·∫∑c `"finetuned"` |
| `threshold` | `float` | `0.75` | Ng∆∞·ª°ng confidence (0.0-1.0). Ch·ªâ tr·∫£ v·ªÅ contradictions c√≥ confidence ‚â• threshold |
| `use_embeddings_filter` | `bool` | `True` | L·ªçc c·∫∑p c√¢u b·∫±ng embedding tr∆∞·ªõc khi ch·∫°y NLI (tƒÉng t·ªëc) |
| `embedding_model_name` | `str` | `"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"` | Model embedding ƒë·ªÉ l·ªçc |
| `top_k` | `int` | `50` | S·ªë l∆∞·ª£ng c·∫∑p c√¢u t·ªëi ƒëa cho m·ªói c√¢u |
| `sim_min` | `float` | `0.30` | ƒê·ªô t∆∞∆°ng ƒë·ªìng embedding t·ªëi thi·ªÉu |
| `sim_max` | `float` | `0.98` | ƒê·ªô t∆∞∆°ng ƒë·ªìng embedding t·ªëi ƒëa |
| `batch_size` | `int` | `8` | Batch size cho NLI inference |
| `max_length` | `int` | `128` | ƒê·ªô d√†i token t·ªëi ƒëa |

### Returns

```python
{
    "success": bool,                    # True n·∫øu th√†nh c√¥ng
    "mode": str,                        # "base" ho·∫∑c "finetuned"
    "model_path": str,                  # Path ƒë·∫øn model ƒë∆∞·ª£c s·ª≠ d·ª•ng
    "text": str,                        # VƒÉn b·∫£n g·ªëc
    "total_sentences": int,             # S·ªë c√¢u ƒë√£ t√°ch
    "sentences": List[str],             # Danh s√°ch c√°c c√¢u
    "total_contradictions": int,        # S·ªë m√¢u thu·∫´n t√¨m th·∫•y
    "contradictions": [                 # Danh s√°ch m√¢u thu·∫´n
        {
            "id": int,                  # ID c·ªßa m√¢u thu·∫´n
            "sentence1_index": int,     # Index c·ªßa c√¢u 1
            "sentence2_index": int,     # Index c·ªßa c√¢u 2
            "sentence1": str,           # N·ªôi dung c√¢u 1
            "sentence2": str,           # N·ªôi dung c√¢u 2
            "confidence": float,        # ƒê·ªô tin c·∫≠y (0.0-1.0)
            "boosted": bool             # True n·∫øu c√≥ xung ƒë·ªôt s·ªë/ng√†y th√°ng
        }
    ],
    "metadata": {
        "analyzed_at": str,             # Timestamp ph√¢n t√≠ch
        "threshold": float,             # Threshold ƒë√£ d√πng
        "error": Optional[str]          # L·ªói n·∫øu c√≥
    }
}
```

---

## üéØ V√≠ d·ª• chi ti·∫øt

### Example 1: Ph√¢n t√≠ch vƒÉn b·∫£n ti·∫øng Vi·ªát c∆° b·∫£n

```python
from app.ai.models.contradictions import check_contradictions

text = """
C√¥ng ty b√°o c√°o l·ª£i nhu·∫≠n tƒÉng 15% trong qu√Ω 1.
C√¥ng ty b·ªã l·ªó n·∫∑ng trong qu√Ω 1.
D·ª± √°n ho√†n th√†nh v√†o th√°ng 3/2024.
D·ª± √°n v·∫´n ƒëang trong giai ƒëo·∫°n ph√°t tri·ªÉn.
"""

result = check_contradictions(text=text, mode="finetuned")

if result['success']:
    print(f"‚úÖ Ph√¢n t√≠ch th√†nh c√¥ng!")
    print(f"üìä Model: {result['mode']}")
    print(f"üìù S·ªë c√¢u: {result['total_sentences']}")
    print(f"‚ö†Ô∏è  S·ªë m√¢u thu·∫´n: {result['total_contradictions']}")
    
    for c in result['contradictions']:
        print(f"\n[{c['id']}] Confidence: {c['confidence']:.2%}")
        print(f"  ‚ùå C√¢u {c['sentence1_index']}: {c['sentence1']}")
        print(f"  ‚ùå C√¢u {c['sentence2_index']}: {c['sentence2']}")
        if c['boosted']:
            print(f"  üî• Ph√°t hi·ªán xung ƒë·ªôt s·ªë li·ªáu/th·ªùi gian!")
else:
    print(f"‚ùå L·ªói: {result['metadata']['error']}")
```

### Example 2: Custom threshold (Strict mode)

```python
# Ch·∫ø ƒë·ªô strict: ch·ªâ l·∫•y m√¢u thu·∫´n c√≥ confidence cao
result_strict = check_contradictions(
    text=text,
    mode="finetuned",
    threshold=0.90  # Ch·ªâ l·∫•y ‚â• 90%
)

print(f"Strict mode: {result_strict['total_contradictions']} contradictions")
```

### Example 3: Relaxed mode (Nhi·ªÅu k·∫øt qu·∫£ h∆°n)

```python
# Ch·∫ø ƒë·ªô relaxed: l·∫•y nhi·ªÅu m√¢u thu·∫´n h∆°n (c√≥ th·ªÉ c√≥ false positives)
result_relaxed = check_contradictions(
    text=text,
    mode="finetuned",
    threshold=0.60  # Ng∆∞·ª°ng th·∫•p h∆°n
)

print(f"Relaxed mode: {result_relaxed['total_contradictions']} contradictions")
```

### Example 4: Kh√¥ng d√πng embedding filter

```python
# Ph√¢n t√≠ch T·∫§T C·∫¢ c√°c c·∫∑p c√¢u (ch·∫≠m v·ªõi vƒÉn b·∫£n d√†i)
result = check_contradictions(
    text=text,
    mode="finetuned",
    use_embeddings_filter=False  # T·∫Øt filter
)

# H·ªØu √≠ch khi vƒÉn b·∫£n ng·∫Øn ho·∫∑c c·∫ßn ƒë·ªô ch√≠nh x√°c cao
```

### Example 5: So s√°nh Base vs Fine-tuned

```python
text = "VƒÉn b·∫£n ti·∫øng Vi·ªát..."

# Base model
result_base = check_contradictions(text=text, mode="base", threshold=0.75)

# Fine-tuned model
result_ft = check_contradictions(text=text, mode="finetuned", threshold=0.75)

print("\n=== SO S√ÅNH ===")
print(f"Base Model:")
print(f"  - Contradictions: {result_base['total_contradictions']}")
if result_base['contradictions']:
    avg_conf_base = sum(c['confidence'] for c in result_base['contradictions']) / len(result_base['contradictions'])
    print(f"  - Avg Confidence: {avg_conf_base:.2%}")

print(f"\nFine-tuned Model:")
print(f"  - Contradictions: {result_ft['total_contradictions']}")
if result_ft['contradictions']:
    avg_conf_ft = sum(c['confidence'] for c in result_ft['contradictions']) / len(result_ft['contradictions'])
    print(f"  - Avg Confidence: {avg_conf_ft:.2%}")
    
if result_base['contradictions'] and result_ft['contradictions']:
    improvement = avg_conf_ft - avg_conf_base
    print(f"\nüìà Improvement: {improvement:+.2%}")
```

---

## ‚öôÔ∏è Quy tr√¨nh x·ª≠ l√Ω

### B∆∞·ªõc 1: T√°ch c√¢u
```
VƒÉn b·∫£n ‚Üí extract_sentences() ‚Üí Danh s√°ch c√¢u
```
- S·ª≠ d·ª•ng regex ƒë·ªÉ t√°ch c√¢u theo d·∫•u `.!?`
- Ch·ªâ gi·ªØ c√¢u c√≥ ‚â•3 t·ª´
- H·ªó tr·ª£ ti·∫øng Vi·ªát (ch·ªØ hoa c√≥ d·∫•u)

### B∆∞·ªõc 2: L·ªçc c·∫∑p c√¢u (n·∫øu `use_embeddings_filter=True`)
```
C√¢u ‚Üí Embedding ‚Üí T√≠nh similarity ‚Üí L·ªçc c·∫∑p c√≥ sim_min ‚â§ similarity ‚â§ sim_max
```
- D√πng sentence-transformers ƒë·ªÉ t·∫°o embedding
- Ch·ªâ ph√¢n t√≠ch c√°c c·∫∑p c√¢u c√≥ ƒë·ªô t∆∞∆°ng ƒë·ªìng ph√π h·ª£p
- Gi·∫£m s·ªë l∆∞·ª£ng c·∫∑p c·∫ßn ph√¢n t√≠ch ‚Üí tƒÉng t·ªëc

### B∆∞·ªõc 3: Ph√¢n t√≠ch NLI
```
C·∫∑p c√¢u ‚Üí NLI Model ‚Üí Contradiction probability
```
- Ch·∫°y c·∫£ 2 chi·ªÅu: A‚ÜíB v√† B‚ÜíA
- L·∫•y max confidence c·ªßa 2 chi·ªÅu
- Boost +5% n·∫øu ph√°t hi·ªán xung ƒë·ªôt s·ªë/ng√†y

### B∆∞·ªõc 4: L·ªçc & S·∫Øp x·∫øp
```
Contradictions ‚Üí Dedup ‚Üí Sort by confidence ‚Üí G√°n ID
```
- Lo·∫°i b·ªè tr√πng l·∫∑p
- S·∫Øp x·∫øp theo confidence gi·∫£m d·∫ßn
- G√°n ID cho m·ªói contradiction

---

## üé® T√πy ch·ªânh n√¢ng cao

### 1. ƒêi·ªÅu ch·ªânh threshold theo use case

```python
# Use case: Ki·ªÉm tra nghi√™m ng·∫∑t (legal documents, contracts)
result = check_contradictions(text, threshold=0.95)  # Ch·ªâ l·∫•y m√¢u thu·∫´n r√µ r√†ng

# Use case: G·ª£i √Ω ch·ªânh s·ª≠a (draft articles, blogs)
result = check_contradictions(text, threshold=0.65)  # L·∫•y nhi·ªÅu h∆°n ƒë·ªÉ review

# Use case: C√¢n b·∫±ng (default)
result = check_contradictions(text, threshold=0.75)  # Khuy√™n d√πng
```

### 2. ƒêi·ªÅu ch·ªânh embedding filter

```python
# VƒÉn b·∫£n ng·∫Øn: T·∫Øt filter
result = check_contradictions(
    text=short_text,
    use_embeddings_filter=False  # Ph√¢n t√≠ch t·∫•t c·∫£
)

# VƒÉn b·∫£n d√†i: Ch·ªânh filter ch·∫∑t h∆°n
result = check_contradictions(
    text=long_text,
    sim_min=0.40,  # TƒÉng threshold
    sim_max=0.95,  # Gi·∫£m max
    top_k=30       # Gi·∫£m s·ªë c·∫∑p
)

# VƒÉn b·∫£n r·∫•t ƒëa d·∫°ng: M·ªü r·ªông filter
result = check_contradictions(
    text=diverse_text,
    sim_min=0.20,  # Gi·∫£m threshold
    sim_max=0.99,  # TƒÉng max
    top_k=100      # TƒÉng s·ªë c·∫∑p
)
```

### 3. X·ª≠ l√Ω k·∫øt qu·∫£

```python
result = check_contradictions(text=text, mode="finetuned")

# L·ªçc theo confidence
high_conf = [c for c in result['contradictions'] if c['confidence'] >= 0.90]
medium_conf = [c for c in result['contradictions'] if 0.75 <= c['confidence'] < 0.90]
low_conf = [c for c in result['contradictions'] if c['confidence'] < 0.75]

print(f"High confidence: {len(high_conf)}")
print(f"Medium confidence: {len(medium_conf)}")
print(f"Low confidence: {len(low_conf)}")

# L·ªçc theo boosted (xung ƒë·ªôt s·ªë/ng√†y)
number_conflicts = [c for c in result['contradictions'] if c['boosted']]
print(f"Number/Date conflicts: {len(number_conflicts)}")

# Export to JSON
import json
with open('contradictions.json', 'w', encoding='utf-8') as f:
    json.dump(result, f, ensure_ascii=False, indent=2)
```

---

## üìä Performance & T·ªëi ∆∞u

### Model Selection

| Model | Use Case | Accuracy (VI) | Speed | Memory |
|-------|----------|---------------|-------|--------|
| **Base** | ƒêa ng√¥n ng·ªØ, Universal | ~72% | Fast | Low |
| **Fine-tuned** | Ti·∫øng Vi·ªát chuy√™n bi·ªát | ~87% | Fast | Low |

### T·ªëc ƒë·ªô

- **VƒÉn b·∫£n ng·∫Øn** (5-10 c√¢u): ~1-2 gi√¢y
- **VƒÉn b·∫£n trung b√¨nh** (20-30 c√¢u): ~3-5 gi√¢y
- **VƒÉn b·∫£n d√†i** (50-100 c√¢u): ~10-20 gi√¢y

**Tips tƒÉng t·ªëc:**
- D√πng `use_embeddings_filter=True` (default)
- Gi·∫£m `top_k` n·∫øu vƒÉn b·∫£n r·∫•t d√†i
- TƒÉng `batch_size` n·∫øu c√≥ GPU m·∫°nh

### GPU vs CPU

```python
import torch

# Check device
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using: {device}")

# GPU: ~3-5x faster than CPU
# Recommended: NVIDIA GPU with CUDA support
```

---

## üîç Troubleshooting

### 1. Kh√¥ng t√¨m th·∫•y m√¢u thu·∫´n n√†o

**Nguy√™n nh√¢n:**
- Threshold qu√° cao
- VƒÉn b·∫£n kh√¥ng c√≥ m√¢u thu·∫´n th·ª±c s·ª±
- Embedding filter qu√° strict

**Gi·∫£i ph√°p:**
```python
# Gi·∫£m threshold
result = check_contradictions(text, threshold=0.65)

# T·∫Øt embedding filter
result = check_contradictions(text, use_embeddings_filter=False)

# M·ªü r·ªông similarity range
result = check_contradictions(text, sim_min=0.20, sim_max=0.99)
```

### 2. Qu√° nhi·ªÅu false positives

**Nguy√™n nh√¢n:**
- Threshold qu√° th·∫•p

**Gi·∫£i ph√°p:**
```python
# TƒÉng threshold
result = check_contradictions(text, threshold=0.85)

# Ch·ªâ l·∫•y high confidence
high_conf = [c for c in result['contradictions'] if c['confidence'] >= 0.90]
```

### 3. Ch·∫≠m v·ªõi vƒÉn b·∫£n d√†i

**Gi·∫£i ph√°p:**
```python
# Gi·∫£m top_k
result = check_contradictions(text, top_k=25)

# TƒÉng sim_min
result = check_contradictions(text, sim_min=0.50)

# TƒÉng batch_size (n·∫øu c√≥ GPU)
result = check_contradictions(text, batch_size=16)
```

### 4. Fine-tuned model kh√¥ng load

**Ki·ªÉm tra:**
```python
from pathlib import Path

model_path = Path("backend/app/ai/fine tune/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7")
print(f"Exists: {model_path.exists()}")

if model_path.exists():
    files = list(model_path.iterdir())
    print(f"Files: {[f.name for f in files]}")
```

**C·∫ßn c√≥:**
- `pytorch_model.bin`
- `config.json`
- `vocab.txt`
- `tokenizer_config.json`

---

## üìù Best Practices

### 1. Ch·ªçn mode ph√π h·ª£p
```python
# Ti·∫øng Vi·ªát ‚Üí d√πng fine-tuned
result = check_contradictions(vietnamese_text, mode="finetuned")

# Ti·∫øng Anh ho·∫∑c ƒëa ng√¥n ng·ªØ ‚Üí d√πng base
result = check_contradictions(english_text, mode="base")
```

### 2. X·ª≠ l√Ω error gracefully
```python
result = check_contradictions(text, mode="finetuned")

if not result['success']:
    print(f"Error: {result['metadata']['error']}")
    # Fallback to base model
    result = check_contradictions(text, mode="base")
```

### 3. Validate input
```python
if not text or len(text.strip()) < 10:
    print("Text too short!")
else:
    result = check_contradictions(text)
```

### 4. Cache results
```python
import hashlib
import json

def get_contradictions_cached(text, mode="finetuned"):
    # Create cache key
    cache_key = hashlib.md5(f"{text}{mode}".encode()).hexdigest()
    cache_file = f"cache/{cache_key}.json"
    
    # Check cache
    if os.path.exists(cache_file):
        with open(cache_file, 'r') as f:
            return json.load(f)
    
    # Compute
    result = check_contradictions(text, mode=mode)
    
    # Save cache
    with open(cache_file, 'w') as f:
        json.dump(result, f)
    
    return result
```

---

## üß™ Testing

### File test m·∫´u: `aiTest.py`

```python
from app.ai.models.contradictions import check_contradictions

text = """
Minh lu√¥n n√≥i r·∫±ng anh ch∆∞a bao gi·ªù r·ªùi kh·ªèi Vi·ªát Nam.
Anh k·ªÉ r·∫±ng l·∫ßn ƒë·∫ßu ƒë·∫øn Nh·∫≠t B·∫£n l√† v√†o nƒÉm 2019.
"""

result = check_contradictions(mode="finetuned", text=text)

print(f"Success: {result['success']}")
print(f"Total Contradictions: {result['total_contradictions']}")

for c in result['contradictions']:
    print(f"[{c['id']}] {c['confidence']:.2%}")
    print(f"  {c['sentence1']}")
    print(f"  {c['sentence2']}")
```

### Ch·∫°y test

```bash
cd backend
python -m app.ai.models.aiTest
```

---

## üìö API Integration

### FastAPI endpoint (example)

```python
from fastapi import APIRouter
from app.ai.models.contradictions import check_contradictions

router = APIRouter()

@router.post("/analyze/contradictions")
async def analyze_contradictions(
    text: str,
    mode: str = "finetuned",
    threshold: float = 0.75
):
    result = check_contradictions(
        text=text,
        mode=mode,
        threshold=threshold
    )
    return result
```

### Usage

```bash
curl -X POST "http://localhost:8000/analyze/contradictions" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "VƒÉn b·∫£n c·∫ßn ph√¢n t√≠ch...",
    "mode": "finetuned",
    "threshold": 0.75
  }'
```

---

## üîó Related Files

- **`contradictions.py`** - Core module
- **`nlp.py`** - Sentence extraction
- **`gemini.py`** - Alternative Gemini-based detection
- **`aiTest.py`** - Test script
- **`fine tune/`** - Fine-tuned model folder

---

## üìû Support

N·∫øu g·∫∑p v·∫•n ƒë·ªÅ:
1. Ki·ªÉm tra error trong `result['metadata']['error']`
2. Th·ª≠ gi·∫£m threshold ho·∫∑c t·∫Øt embedding filter
3. Verify model path v·ªõi Base model
4. Check GPU/CUDA availability

---

**T√≥m t·∫Øt:**
- D√πng `mode="finetuned"` cho ti·∫øng Vi·ªát (accuracy cao h∆°n ~20%)
- `threshold=0.75` l√† gi√° tr·ªã c√¢n b·∫±ng t·ªët
- `use_embeddings_filter=True` ƒë·ªÉ tƒÉng t·ªëc
- Lu√¥n check `result['success']` tr∆∞·ªõc khi x·ª≠ l√Ω k·∫øt qu·∫£
