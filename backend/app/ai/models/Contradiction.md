# HÆ°á»›ng dáº«n sá»­ dá»¥ng Contradiction Detection (Optimized Version)

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### 1ï¸âƒ£ **CÆ¡ báº£n - Single Text**

```python
from app.ai.models.contradictions import check_contradictions

text = """
Minh nÃ³i chÆ°a bao giá» rá»i khá»i Viá»‡t Nam.
Anh ká»ƒ láº§n Ä‘áº§u Ä‘áº¿n Nháº­t Báº£n lÃ  nÄƒm 2019.
"""

result = check_contradictions(
    text=text,
    mode="finetuned"  # hoáº·c "base"
)

if result['success']:
    print(f"TÃ¬m tháº¥y {result['total_contradictions']} mÃ¢u thuáº«n")
    for c in result['contradictions']:
        print(f"- {c['sentence1']}")
        print(f"- {c['sentence2']}")
        print(f"  Confidence: {c['confidence']:.2%}\n")
```


### 2ï¸âƒ£ **Tá»‘i Æ°u - Multiple Texts**

```python
from app.ai.models.contradictions import check_contradictions, clear_model_cache

texts = [
    "Text 1...",
    "Text 2...",
    "Text 3...",
]

# Process nhiá»u texts - model chá»‰ load 1 láº§n
for text in texts:
    result = check_contradictions(text, mode="finetuned")
    # Xá»­ lÃ½ result...

# Clear cache khi xong
clear_model_cache()
```

**Performance:**
- Text 1: ~10s (load models)
- Text 2: ~2s (cached)
- Text 3: ~2s (cached)
- **Speedup: 5x faster!** 

---

### 3ï¸âƒ£ **Production - API Endpoint**

```python
# app/routers/analysis.py
from fastapi import APIRouter
from app.ai.models.contradictions import check_contradictions

router = APIRouter()

@router.post("/analyze")
async def analyze_text(text: str, mode: str = "finetuned"):
    """
    API endpoint - model cached across requests
    Má»—i request chá»‰ máº¥t ~1-3s thay vÃ¬ ~10-15s
    """
    result = check_contradictions(text, mode=mode)
    return result
```

**Lá»£i Ã­ch:**
- Request Ä‘áº§u: ~10s (load models 1 láº§n)
- CÃ¡c request sau: ~1-3s (dÃ¹ng cache)
- KhÃ´ng cáº§n restart server
- Auto memory management

---

### 4ï¸âƒ£ **Advanced - Custom Parameters**

```python
result = check_contradictions(
    text=text,
    mode="finetuned",           # "base" | "finetuned"
    threshold=0.75,              # NgÆ°á»¡ng confidence (0.0-1.0)
    use_embeddings_filter=True,  # Lá»c cáº·p cÃ¢u báº±ng embedding
    top_k=50,                    # Sá»‘ cáº·p tá»‘i Ä‘a cho má»—i cÃ¢u
    sim_min=0.30,                # Äá»™ tÆ°Æ¡ng Ä‘á»“ng tá»‘i thiá»ƒu
    sim_max=0.98,                # Äá»™ tÆ°Æ¡ng Ä‘á»“ng tá»‘i Ä‘a
    batch_size=8,                # KÃ­ch thÆ°á»›c batch
    max_length=128,              # Äá»™ dÃ i tá»‘i Ä‘a cá»§a cÃ¢u
)
```

---

## ğŸ”§ Quáº£n lÃ½ Cache

### Clear cache thá»§ cÃ´ng

```python
from app.ai.models.contradictions import clear_model_cache

# XÃ³a toÃ n bá»™ cached models
clear_model_cache()
```

**Khi nÃ o cáº§n clear?**
- âœ… Khi Ä‘á»•i mode (base â†” finetuned) nhiá»u láº§n
- âœ… Khi háº¿t dÃ¹ng vÃ  muá»‘n giáº£i phÃ³ng RAM/GPU
- âœ… Khi cháº¡y batch job xong
- âŒ KhÃ´ng cáº§n clear giá»¯a cÃ¡c requests (API sáº½ tá»± quáº£n lÃ½)

### Auto memory management

Code tá»± Ä‘á»™ng kiá»ƒm tra vÃ  clear cache khi:
- GPU memory usage > 80%
- TrÃ¡nh OOM (Out of Memory)

---

## ğŸ“Š Response Format

```json
{
  "success": true,
  "mode": "finetuned",
  "model_path": "duowng/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7-for-vietnamese",
  "text": "...",
  "total_sentences": 10,
  "sentences": ["CÃ¢u 1", "CÃ¢u 2", ...],
  "total_contradictions": 5,
  "contradictions": [
    {
      "id": 1,
      "sentence1_index": 0,
      "sentence2_index": 1,
      "sentence1": "CÃ¢u mÃ¢u thuáº«n thá»© nháº¥t",
      "sentence2": "CÃ¢u mÃ¢u thuáº«n thá»© hai",
      "confidence": 0.9523,
      "boosted": false
    }
  ],
  "metadata": {
    "analyzed_at": "2025-10-27T10:30:00",
    "threshold": 0.75,
    "error": null
  }
}
```

---

## ğŸ’¡ Best Practices

### âœ… DO

```python
# 1. TÃ¡i sá»­ dá»¥ng function cho nhiá»u texts
for text in texts:
    result = check_contradictions(text, mode="finetuned")

# 2. Clear cache sau khi xong batch
clear_model_cache()

# 3. DÃ¹ng mode="finetuned" cho tiáº¿ng Viá»‡t
result = check_contradictions(text, mode="finetuned")
```

### âŒ DON'T

```python
# 1. Äá»«ng clear cache giá»¯a cÃ¡c requests
result1 = check_contradictions(text1)
clear_model_cache()  # âŒ Sai - lÃ m cháº­m request tiáº¿p theo
result2 = check_contradictions(text2)

# 2. Äá»«ng load láº¡i model má»—i láº§n
# Code cÅ©:
model = load_model()  # âŒ Cháº­m
result = analyze(text, model)

# Code má»›i:
result = check_contradictions(text)  # âœ… Nhanh (cached)
```

---

## ğŸ¯ Performance Comparison

| Scenario | Before (No Cache) | After (With Cache) | Speedup |
|----------|-------------------|-------------------|---------|
| Single text | ~10-15s | ~10-15s | 1x |
| 10 texts | ~100-150s | ~25-35s | **4-5x** âš¡ |
| API (100 req) | ~1000-1500s | ~150-250s | **5-7x** ğŸš€ |

---

## ğŸ› Troubleshooting

### Model khÃ´ng load?
```python
# Check Hugging Face connection
from transformers import AutoModel
model = AutoModel.from_pretrained("duowng/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7-for-vietnamese")
```

### Out of Memory?
```python
# Clear cache thá»§ cÃ´ng
from app.ai.models.contradictions import clear_model_cache
clear_model_cache()
```

### Code cháº¡y cháº­m?
- Láº§n Ä‘áº§u: BÃ¬nh thÆ°á»ng (~10-15s load models)
- Láº§n sau váº«n cháº­m: Check xem cÃ³ clear cache giá»¯a chá»«ng khÃ´ng?

---

## ğŸ“ Support

- Documentation: `Contradiction.md`
- Test script: `aiTest.py`
- Optimized example: `testOptimized.py`

---

**Version:** 2.0 (Optimized with Caching)  
**Last Updated:** 2025-10-27
