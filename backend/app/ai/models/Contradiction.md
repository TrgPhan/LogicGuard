# H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng Contradiction Detection (Optimized Version)

## üöÄ C√°ch s·ª≠ d·ª•ng

H·ªá th·ªëng ph√°t hi·ªán m√¢u thu·∫´n (Contradiction Detection) s·ª≠ d·ª•ng **Natural Language Inference (NLI)** model ƒë·ªÉ ph√¢n t√≠ch vƒÉn b·∫£n v√† t√¨m c√°c c√¢u m√¢u thu·∫´n v·ªõi nhau.

### C√°c th√†nh ph·∫ßn ch√≠nh:

1. **`contradictions.py`** - Core module ch·ª©a h√†m ph√¢n t√≠ch ch√≠nh
2. **`nlp.py`** - Utils ƒë·ªÉ t√°ch c√¢u t·ª´ vƒÉn b·∫£n
3. **Models:**
   - **Base Model**: `MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7` (ƒêa ng√¥n ng·ªØ)
   - **Fine-tuned Model**: Model ƒë√£ fine-tune cho ti·∫øng Vi·ªát (trong `fine tune/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/`)

---

## üöÄ C√°ch s·ª≠ d·ª•ng c∆° b·∫£n

### 1. Import

```python
from app.ai.models.contradictions import check_contradictions
```

### 2. S·ª≠ d·ª•ng Fine-tuned Model (Khuy√™n d√πng cho ti·∫øng Vi·ªát)

```python
text = """
Minh lu√¥n n√≥i r·∫±ng anh ch∆∞a bao gi·ªù r·ªùi kh·ªèi Vi·ªát Nam.
Anh k·ªÉ r·∫±ng l·∫ßn ƒë·∫ßu ƒë·∫øn Nh·∫≠t B·∫£n l√† v√†o nƒÉm 2019.
Anh cho bi·∫øt m√¨nh gh√©t s·ª± ·ªìn √†o n√™n hi·∫øm khi ra ngo√†i v√†o bu·ªïi t·ªëi.
T·ªëi n√†o Minh c≈©ng ƒëi u·ªëng c√† ph√™ c√πng b·∫°n b√® ƒë·ªÉ th∆∞ gi√£n.
"""

result = check_contradictions(
    text=text,
    mode="finetuned",  # S·ª≠ d·ª•ng fine-tuned model
    threshold=0.75
)

# In k·∫øt qu·∫£
print(f"T√¨m th·∫•y {result['total_contradictions']} m√¢u thu·∫´n")
for c in result['contradictions']:
    print(f"- [{c['id']}] Confidence: {c['confidence']:.2%}")
    print(f"  C√¢u {c['sentence1_index']}: {c['sentence1']}")
    print(f"  C√¢u {c['sentence2_index']}: {c['sentence2']}")
```

### 3. S·ª≠ d·ª•ng Base Model

```python
result = check_contradictions(
    text=text,
    mode="base",  # S·ª≠ d·ª•ng base model
    threshold=0.75
)
```

---

## üìñ H√†m `check_contradictions()`

### Signature

```python
def check_contradictions(
    text: str,
    mode: str = "finetuned",
    threshold: float = 0.75,
    use_embeddings_filter: bool = True,
    embedding_model_name: str = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
    top_k: int = 50,
    sim_min: float = 0.30,
    sim_max: float = 0.98,
    batch_size: int = 8,
    max_length: int = 128,
) -> Dict[str, Any]
```

### Parameters

| Parameter               | Type    | Default                                                         | M√¥ t·∫£                                                                            |
| ----------------------- | ------- | --------------------------------------------------------------- | -------------------------------------------------------------------------------- |
| `text`                  | `str`   | **required**                                                    | ƒêo·∫°n vƒÉn b·∫£n c·∫ßn ph√¢n t√≠ch                                                       |
| `mode`                  | `str`   | `"finetuned"`                                                   | Ch·∫ø ƒë·ªô model: `"base"` ho·∫∑c `"finetuned"`                                        |
| `threshold`             | `float` | `0.75`                                                          | Ng∆∞·ª°ng confidence (0.0-1.0). Ch·ªâ tr·∫£ v·ªÅ contradictions c√≥ confidence ‚â• threshold |
| `use_embeddings_filter` | `bool`  | `True`                                                          | L·ªçc c·∫∑p c√¢u b·∫±ng embedding tr∆∞·ªõc khi ch·∫°y NLI (tƒÉng t·ªëc)                         |
| `embedding_model_name`  | `str`   | `"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"` | Model embedding ƒë·ªÉ l·ªçc                                                           |
| `top_k`                 | `int`   | `50`                                                            | S·ªë l∆∞·ª£ng c·∫∑p c√¢u t·ªëi ƒëa cho m·ªói c√¢u                                              |
| `sim_min`               | `float` | `0.30`                                                          | ƒê·ªô t∆∞∆°ng ƒë·ªìng embedding t·ªëi thi·ªÉu                                                |
| `sim_max`               | `float` | `0.98`                                                          | ƒê·ªô t∆∞∆°ng ƒë·ªìng embedding t·ªëi ƒëa                                                   |
| `batch_size`            | `int`   | `8`                                                             | Batch size cho NLI inference                                                     |
| `max_length`            | `int`   | `128`                                                           | ƒê·ªô d√†i token t·ªëi ƒëa                                                              |

### Returns

```python
{
    "success": bool,                    # True n·∫øu th√†nh c√¥ng
    "mode": str,                        # "base" ho·∫∑c "finetuned"
    "model_path": str,                  # Path ƒë·∫øn model ƒë∆∞·ª£c s·ª≠ d·ª•ng
    "text": str,                        # VƒÉn b·∫£n g·ªëc
    "total_sentences": int,             # S·ªë c√¢u ƒë√£ t√°ch
    "sentences": List[str],             # Danh s√°ch c√°c c√¢u
    "total_contradictions": int,        # S·ªë m√¢u thu·∫´n t√¨m th·∫•y
    "contradictions": [                 # Danh s√°ch m√¢u thu·∫´n
        {
            "id": int,                  # ID c·ªßa m√¢u thu·∫´n
            "sentence1_index": int,     # Index c·ªßa c√¢u 1
            "sentence2_index": int,     # Index c·ªßa c√¢u 2
            "sentence1": str,           # N·ªôi dung c√¢u 1
            "sentence2": str,           # N·ªôi dung c√¢u 2
            "confidence": float,        # ƒê·ªô tin c·∫≠y (0.0-1.0)
            "boosted": bool             # True n·∫øu c√≥ xung ƒë·ªôt s·ªë/ng√†y th√°ng
        }
    ],
    "metadata": {
        "analyzed_at": str,             # Timestamp ph√¢n t√≠ch
        "threshold": float,             # Threshold ƒë√£ d√πng
        "error": Optional[str]          # L·ªói n·∫øu c√≥
    }
}
```

---

## üéØ V√≠ d·ª• chi ti·∫øt

### 1Ô∏è‚É£ **C∆° b·∫£n - Single Text**

```python
from app.ai.models.contradictions import check_contradictions

text = """
Minh n√≥i ch∆∞a bao gi·ªù r·ªùi kh·ªèi Vi·ªát Nam.
Anh k·ªÉ l·∫ßn ƒë·∫ßu ƒë·∫øn Nh·∫≠t B·∫£n l√† nƒÉm 2019.
"""

result = check_contradictions(
    text=text,
    mode="finetuned"  # ho·∫∑c "base"
)

if result['success']:
    print(f"‚úÖ Ph√¢n t√≠ch th√†nh c√¥ng!")
    print(f"üìä Model: {result['mode']}")
    print(f"üìù S·ªë c√¢u: {result['total_sentences']}")
    print(f"T√¨m th·∫•y {result['total_contradictions']} m√¢u thu·∫´n")
    print(f"‚ö†Ô∏è  S·ªë m√¢u thu·∫´n: {result['total_contradictions']}")
    for c in result['contradictions']:
        print(f"- {c['sentence1']}")
        print(f"- {c['sentence2']}")
        print(f"  Confidence: {c['confidence']:.2%}\n")
```

### 2Ô∏è‚É£ **T·ªëi ∆∞u - Multiple Texts**

```python
from app.ai.models.contradictions import check_contradictions, clear_model_cache

texts = [
    "Text 1...",
    "Text 2...",
    "Text 3...",
]

# Process nhi·ªÅu texts - model ch·ªâ load 1 l·∫ßn
for text in texts:
    result = check_contradictions(text, mode="finetuned")
    # X·ª≠ l√Ω result...

# Clear cache khi xong
clear_model_cache()
```

**Performance (cache demo):**

- Text 1: ~10s (load models)
- Text 2: ~2s (cached)
- Text 3: ~2s (cached)
- üëâ T·∫≠n d·ª•ng cache gi√∫p tƒÉng t·ªëc ~5x

---

### Example 3: Relaxed mode (Nhi·ªÅu k·∫øt qu·∫£ h∆°n)

```python
# Ch·∫ø ƒë·ªô relaxed: l·∫•y nhi·ªÅu m√¢u thu·∫´n h∆°n (c√≥ th·ªÉ c√≥ false positives)
result_relaxed = check_contradictions(
    text=text,
    mode="finetuned",
    threshold=0.60  # Ng∆∞·ª°ng th·∫•p h∆°n
)

print(f"Relaxed mode: {result_relaxed['total_contradictions']} contradictions")
```

### Example 4: Kh√¥ng d√πng embedding filter

```python
# Ph√¢n t√≠ch T·∫§T C·∫¢ c√°c c·∫∑p c√¢u (ch·∫≠m v·ªõi vƒÉn b·∫£n d√†i)
result = check_contradictions(
    text=text,
    mode="finetuned",
    use_embeddings_filter=False  # T·∫Øt filter
)

# H·ªØu √≠ch khi vƒÉn b·∫£n ng·∫Øn ho·∫∑c c·∫ßn ƒë·ªô ch√≠nh x√°c cao
```

### Example 5: So s√°nh Base vs Fine-tuned

```python
text = "VƒÉn b·∫£n ti·∫øng Vi·ªát..."

# Base model
result_base = check_contradictions(text=text, mode="base", threshold=0.75)

# Fine-tuned model
result_ft = check_contradictions(text=text, mode="finetuned", threshold=0.75)

print("\n=== SO S√ÅNH ===")
print(f"Base Model:")
print(f"  - Contradictions: {result_base['total_contradictions']}")
if result_base['contradictions']:
    avg_conf_base = sum(c['confidence'] for c in result_base['contradictions']) / len(result_base['contradictions'])
    print(f"  - Avg Confidence: {avg_conf_base:.2%}")

print(f"\nFine-tuned Model:")
print(f"  - Contradictions: {result_ft['total_contradictions']}")
if result_ft['contradictions']:
    avg_conf_ft = sum(c['confidence'] for c in result_ft['contradictions']) / len(result_ft['contradictions'])
    print(f"  - Avg Confidence: {avg_conf_ft:.2%}")

if result_base['contradictions'] and result_ft['contradictions']:
    improvement = avg_conf_ft - avg_conf_base
    print(f"\nüìà Improvement: {improvement:+.2%}")
```

---

## ‚öôÔ∏è Quy tr√¨nh x·ª≠ l√Ω

### B∆∞·ªõc 1: T√°ch c√¢u

```
VƒÉn b·∫£n ‚Üí extract_sentences() ‚Üí Danh s√°ch c√¢u
```

- S·ª≠ d·ª•ng regex ƒë·ªÉ t√°ch c√¢u theo d·∫•u `.!?`
- Ch·ªâ gi·ªØ c√¢u c√≥ ‚â•3 t·ª´
- H·ªó tr·ª£ ti·∫øng Vi·ªát (ch·ªØ hoa c√≥ d·∫•u)

### B∆∞·ªõc 2: L·ªçc c·∫∑p c√¢u (n·∫øu `use_embeddings_filter=True`)

```
C√¢u ‚Üí Embedding ‚Üí T√≠nh similarity ‚Üí L·ªçc c·∫∑p c√≥ sim_min ‚â§ similarity ‚â§ sim_max
```

- D√πng sentence-transformers ƒë·ªÉ t·∫°o embedding
- Ch·ªâ ph√¢n t√≠ch c√°c c·∫∑p c√¢u c√≥ ƒë·ªô t∆∞∆°ng ƒë·ªìng ph√π h·ª£p
- Gi·∫£m s·ªë l∆∞·ª£ng c·∫∑p c·∫ßn ph√¢n t√≠ch ‚Üí tƒÉng t·ªëc

### B∆∞·ªõc 3: Ph√¢n t√≠ch NLI

```
C·∫∑p c√¢u ‚Üí NLI Model ‚Üí Contradiction probability
```

- Ch·∫°y c·∫£ 2 chi·ªÅu: A‚ÜíB v√† B‚ÜíA
- L·∫•y max confidence c·ªßa 2 chi·ªÅu
- Boost +5% n·∫øu ph√°t hi·ªán xung ƒë·ªôt s·ªë/ng√†y

### B∆∞·ªõc 4: L·ªçc & S·∫Øp x·∫øp

```
Contradictions ‚Üí Dedup ‚Üí Sort by confidence ‚Üí G√°n ID
```

- Lo·∫°i b·ªè tr√πng l·∫∑p
- S·∫Øp x·∫øp theo confidence gi·∫£m d·∫ßn
- G√°n ID cho m·ªói contradiction

---

## üé® T√πy ch·ªânh n√¢ng cao

### 1. ƒêi·ªÅu ch·ªânh threshold theo use case

```python
# Use case: Ki·ªÉm tra nghi√™m ng·∫∑t (legal documents, contracts)
result = check_contradictions(text, threshold=0.95)  # Ch·ªâ l·∫•y m√¢u thu·∫´n r√µ r√†ng

# Use case: G·ª£i √Ω ch·ªânh s·ª≠a (draft articles, blogs)
result = check_contradictions(text, threshold=0.65)  # L·∫•y nhi·ªÅu h∆°n ƒë·ªÉ review

# Use case: C√¢n b·∫±ng (default)
result = check_contradictions(text, threshold=0.75)  # Khuy√™n d√πng
```

### 2. ƒêi·ªÅu ch·ªânh embedding filter

```python
# VƒÉn b·∫£n ng·∫Øn: T·∫Øt filter
result = check_contradictions(
    text=short_text,
    use_embeddings_filter=False  # Ph√¢n t√≠ch t·∫•t c·∫£
)

# VƒÉn b·∫£n d√†i: Ch·ªânh filter ch·∫∑t h∆°n
result = check_contradictions(
    text=long_text,
    sim_min=0.40,  # TƒÉng threshold
    sim_max=0.95,  # Gi·∫£m max
    top_k=30       # Gi·∫£m s·ªë c·∫∑p
)

# VƒÉn b·∫£n r·∫•t ƒëa d·∫°ng: M·ªü r·ªông filter
result = check_contradictions(
    text=diverse_text,
    sim_min=0.20,  # Gi·∫£m threshold
    sim_max=0.99,  # TƒÉng max
    top_k=100      # TƒÉng s·ªë c·∫∑p
)
```

### 3. X·ª≠ l√Ω k·∫øt qu·∫£

```python
result = check_contradictions(text=text, mode="finetuned")

# L·ªçc theo confidence
high_conf = [c for c in result['contradictions'] if c['confidence'] >= 0.90]
medium_conf = [c for c in result['contradictions'] if 0.75 <= c['confidence'] < 0.90]
low_conf = [c for c in result['contradictions'] if c['confidence'] < 0.75]

print(f"High confidence: {len(high_conf)}")
print(f"Medium confidence: {len(medium_conf)}")
print(f"Low confidence: {len(low_conf)}")

# L·ªçc theo boosted (xung ƒë·ªôt s·ªë/ng√†y)
number_conflicts = [c for c in result['contradictions'] if c['boosted']]
print(f"Number/Date conflicts: {len(number_conflicts)}")

# Export to JSON
import json
with open('contradictions.json', 'w', encoding='utf-8') as f:
    json.dump(result, f, ensure_ascii=False, indent=2)
```

---

## üìä Performance & T·ªëi ∆∞u

### Model Selection

| Model          | Use Case               | Accuracy (VI) | Speed | Memory |
| -------------- | ---------------------- | ------------- | ----- | ------ |
| **Base**       | ƒêa ng√¥n ng·ªØ, Universal | ~72%          | Fast  | Low    |
| **Fine-tuned** | Ti·∫øng Vi·ªát chuy√™n bi·ªát | ~87%          | Fast  | Low    |

### T·ªëc ƒë·ªô

- **VƒÉn b·∫£n ng·∫Øn** (5-10 c√¢u): ~1-2 gi√¢y
- **VƒÉn b·∫£n trung b√¨nh** (20-30 c√¢u): ~3-5 gi√¢y
- **VƒÉn b·∫£n d√†i** (50-100 c√¢u): ~10-20 gi√¢y

**Tips tƒÉng t·ªëc:**

- D√πng `use_embeddings_filter=True` (default)
- Gi·∫£m `top_k` n·∫øu vƒÉn b·∫£n r·∫•t d√†i
- TƒÉng `batch_size` n·∫øu c√≥ GPU m·∫°nh

### GPU vs CPU

```python
import torch

# Check device
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using: {device}")

# GPU: ~3-5x faster than CPU
# Recommended: NVIDIA GPU with CUDA support
```

---

## üîç Troubleshooting

### 1. Kh√¥ng t√¨m th·∫•y m√¢u thu·∫´n n√†o

**Nguy√™n nh√¢n:**

- Threshold qu√° cao
- VƒÉn b·∫£n kh√¥ng c√≥ m√¢u thu·∫´n th·ª±c s·ª±
- Embedding filter qu√° strict

**Gi·∫£i ph√°p:**

```python
# Gi·∫£m threshold
result = check_contradictions(text, threshold=0.65)

# T·∫Øt embedding filter
result = check_contradictions(text, use_embeddings_filter=False)

# M·ªü r·ªông similarity range
result = check_contradictions(text, sim_min=0.20, sim_max=0.99)
```

### 2. Qu√° nhi·ªÅu false positives

**Nguy√™n nh√¢n:**

- Threshold qu√° th·∫•p

**Gi·∫£i ph√°p:**

```python
# TƒÉng threshold
result = check_contradictions(text, threshold=0.85)

# Ch·ªâ l·∫•y high confidence
high_conf = [c for c in result['contradictions'] if c['confidence'] >= 0.90]
```

### 3. Ch·∫≠m v·ªõi vƒÉn b·∫£n d√†i

**Gi·∫£i ph√°p:**

```python
# Gi·∫£m top_k
result = check_contradictions(text, top_k=25)

# TƒÉng sim_min
result = check_contradictions(text, sim_min=0.50)

# TƒÉng batch_size (n·∫øu c√≥ GPU)
result = check_contradictions(text, batch_size=16)
```

### 4. Fine-tuned model kh√¥ng load

**Ki·ªÉm tra:**

```python
from pathlib import Path

model_path = Path("backend/app/ai/fine tune/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7")
print(f"Exists: {model_path.exists()}")

if model_path.exists():
    files = list(model_path.iterdir())
    print(f"Files: {[f.name for f in files]}")
```

**C·∫ßn c√≥:**

- `pytorch_model.bin`
- `config.json`
- `vocab.txt`
- `tokenizer_config.json`

---

## üìù Best Practices

### 1. Ch·ªçn mode ph√π h·ª£p

```python
# Ti·∫øng Vi·ªát ‚Üí d√πng fine-tuned
result = check_contradictions(vietnamese_text, mode="finetuned")

# Ti·∫øng Anh ho·∫∑c ƒëa ng√¥n ng·ªØ ‚Üí d√πng base
result = check_contradictions(english_text, mode="base")
```

### 2. X·ª≠ l√Ω error gracefully

```python
result = check_contradictions(text, mode="finetuned")

if not result['success']:
    print(f"Error: {result['metadata']['error']}")
    # Fallback to base model
    result = check_contradictions(text, mode="base")
```

### 3. Validate input

```python
if not text or len(text.strip()) < 10:
    print("Text too short!")
else:
    result = check_contradictions(text)
```

### 4. Cache results

```python
import hashlib
import json

def get_contradictions_cached(text, mode="finetuned"):
    # Create cache key
    cache_key = hashlib.md5(f"{text}{mode}".encode()).hexdigest()
    cache_file = f"cache/{cache_key}.json"

    # Check cache
    if os.path.exists(cache_file):
        with open(cache_file, 'r') as f:
            return json.load(f)

    # Compute
    result = check_contradictions(text, mode=mode)

    # Save cache
    with open(cache_file, 'w') as f:
        json.dump(result, f)

    return result
```

---

## üìö API Integration

### 3Ô∏è‚É£ **Production - API Endpoint**

```python
# app/routers/analysis.py
from fastapi import APIRouter
from app.ai.models.contradictions import check_contradictions

router = APIRouter()

@router.post("/analyze")
async def analyze_text(text: str, mode: str = "finetuned"):
    """
    API endpoint - model cached across requests
    M·ªói request ch·ªâ m·∫•t ~1-3s thay v√¨ ~10-15s
    """
    result = check_contradictions(text, mode=mode)
    return result
```

**L·ª£i √≠ch:**

- Request ƒë·∫ßu: ~10s (load models 1 l·∫ßn)
- C√°c request sau: ~1-3s (d√πng cache)
- Kh√¥ng c·∫ßn restart server
- Auto memory management

---

### 4Ô∏è‚É£ **Advanced - Custom Parameters**

```python
result = check_contradictions(
    text=text,
    mode="finetuned",           # "base" | "finetuned"
    threshold=0.75,              # Ng∆∞·ª°ng confidence (0.0-1.0)
    use_embeddings_filter=True,  # L·ªçc c·∫∑p c√¢u b·∫±ng embedding
    top_k=50,                    # S·ªë c·∫∑p t·ªëi ƒëa cho m·ªói c√¢u
    sim_min=0.30,                # ƒê·ªô t∆∞∆°ng ƒë·ªìng t·ªëi thi·ªÉu
    sim_max=0.98,                # ƒê·ªô t∆∞∆°ng ƒë·ªìng t·ªëi ƒëa
    batch_size=8,                # K√≠ch th∆∞·ªõc batch
    max_length=128,              # ƒê·ªô d√†i t·ªëi ƒëa c·ªßa c√¢u
)
```

---

## üîß Qu·∫£n l√Ω Cache

### Clear cache th·ªß c√¥ng

```python
from app.ai.models.contradictions import clear_model_cache

# X√≥a to√†n b·ªô cached models
clear_model_cache()
```

**Khi n√†o c·∫ßn clear?**

- ‚úÖ Khi ƒë·ªïi mode (base ‚Üî finetuned) nhi·ªÅu l·∫ßn
- ‚úÖ Khi h·∫øt d√πng v√† mu·ªën gi·∫£i ph√≥ng RAM/GPU
- ‚úÖ Khi ch·∫°y batch job xong
- ‚ùå Kh√¥ng c·∫ßn clear gi·ªØa c√°c requests (API s·∫Ω t·ª± qu·∫£n l√Ω)

### Auto memory management

Code t·ª± ƒë·ªông ki·ªÉm tra v√† clear cache khi:

- GPU memory usage > 80%
- Tr√°nh OOM (Out of Memory)

---

## üìä Response Format

```json
{
  "success": true,
  "mode": "finetuned",
  "model_path": "duowng/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7-for-vietnamese",
  "text": "...",
  "total_sentences": 10,
  "sentences": ["C√¢u 1", "C√¢u 2", ...],
  "total_contradictions": 5,
  "contradictions": [
    {
      "id": 1,
      "sentence1_index": 0,
      "sentence2_index": 1,
      "sentence1": "C√¢u m√¢u thu·∫´n th·ª© nh·∫•t",
      "sentence2": "C√¢u m√¢u thu·∫´n th·ª© hai",
      "confidence": 0.9523,
      "boosted": false
    }
  ],
  "metadata": {
    "analyzed_at": "2025-10-27T10:30:00",
    "threshold": 0.75,
    "error": null
  }
}
```

---

## üí° Best Practices

### ‚úÖ DO

```python
# 1. T√°i s·ª≠ d·ª•ng function cho nhi·ªÅu texts
for text in texts:
    result = check_contradictions(text, mode="finetuned")

# 2. Clear cache sau khi xong batch
clear_model_cache()

# 3. D√πng mode="finetuned" cho ti·∫øng Vi·ªát
result = check_contradictions(text, mode="finetuned")
```

### ‚ùå DON'T

```python
# 1. ƒê·ª´ng clear cache gi·ªØa c√°c requests
result1 = check_contradictions(text1)
clear_model_cache()  # ‚ùå Sai - l√†m ch·∫≠m request ti·∫øp theo
result2 = check_contradictions(text2)

# 2. ƒê·ª´ng load l·∫°i model m·ªói l·∫ßn
# Code c≈©:
model = load_model()  # ‚ùå Ch·∫≠m
result = analyze(text, model)

# Code m·ªõi:
result = check_contradictions(text)  # ‚úÖ Nhanh (cached)
```

---

## üéØ Performance Comparison

| Scenario      | Before (No Cache) | After (With Cache) | Speedup     |
| ------------- | ----------------- | ------------------ | ----------- |
| Single text   | ~10-15s           | ~10-15s            | 1x          |
| 10 texts      | ~100-150s         | ~25-35s            | **4-5x** ‚ö° |
| API (100 req) | ~1000-1500s       | ~150-250s          | **5-7x** üöÄ |

---

## üêõ Troubleshooting

### Model kh√¥ng load?

```python
# Check Hugging Face connection
from transformers import AutoModel
model = AutoModel.from_pretrained("duowng/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7-for-vietnamese")
```

### Out of Memory?

```python
# Clear cache th·ªß c√¥ng
from app.ai.models.contradictions import clear_model_cache
clear_model_cache()
```

### Code ch·∫°y ch·∫≠m?

- L·∫ßn ƒë·∫ßu: B√¨nh th∆∞·ªùng (~10-15s load models)
- L·∫ßn sau v·∫´n ch·∫≠m: Check xem c√≥ clear cache gi·ªØa ch·ª´ng kh√¥ng?

---

## üìû Support

N·∫øu g·∫∑p v·∫•n ƒë·ªÅ:

1. Ki·ªÉm tra error trong `result['metadata']['error']`
2. Th·ª≠ gi·∫£m threshold ho·∫∑c t·∫Øt embedding filter
3. Verify model path v·ªõi Base model
4. Check GPU/CUDA availability

T√†i li·ªáu nhanh:

- Documentation: `Contradiction.md`
- Test script: `aiTest.py`
- Optimized example: `testOptimized.py`

---

**T√≥m t·∫Øt:**

- D√πng `mode="finetuned"` cho ti·∫øng Vi·ªát (accuracy cao h∆°n ~20%)
- `threshold=0.75` l√† gi√° tr·ªã c√¢n b·∫±ng t·ªët
- `use_embeddings_filter=True` ƒë·ªÉ tƒÉng t·ªëc
- Lu√¥n check `result['success']` tr∆∞·ªõc khi x·ª≠ l√Ω k·∫øt qu·∫£

**Version:** 2.0 (Optimized with Caching)  
**Last Updated:** 2025-10-27
